# 机器学习中的误差是怎么来的

* 这里我们把f\*看做是采样得到的样本数据，机器学习的目的其实就是得到这样一个f\*来拟合真实的函数f，但是收到数据和模型定义的影响，f\*最后表现出来的位置是不同的
* 复杂的模型去拟合少量的数据为了使的error小，会出现过拟合的现象，这样即使当数据偏移得很小，输出也会偏移得很大，所以不同的采样数据会因为这个特点造成模型训练出来的效果差异性很大 ，散布得很开，这样variance就变大了
* 简单模型相应的variance就会小很多
* error的另一个来源是bias，表示模型期望和实际函数的差距大小，从目前来看，复杂的模型bias较小，简单的模型bias较大，因为简单model的set大小小于复杂model的set大小
* 少根据public training set的结果去调整参数，这样public training set 和 private training set的表现结果会比较一致

 